# Core Framework
streamlit>=1.28.0
streamlit-aggrid>=0.3.4

# Computer Vision and ML
torch>=2.0.0
torchvision>=0.15.0
ultralytics>=8.0.0
opencv-python>=4.8.0
pillow>=10.0.0
numpy>=1.24.0
scikit-learn>=1.3.0

# Vision Models
open-clip-torch>=2.20.0
transformers>=4.35.0

# API and Web
requests>=2.31.0
aiohttp>=3.8.0
google-search-results>=2.4.2
openai>=1.0.0

# Data Processing
pandas>=2.0.0
bottleneck>=1.5.0

# LangChain Components
langchain>=0.1.0
langchain-openai>=0.0.2
langchain-community>=0.0.10

# Environment and Configuration
python-dotenv>=1.0.0
pydantic>=2.0.0

# Image Processing
imageio>=2.31.0
matplotlib>=3.7.0

# Caching and Performance
functools32; python_version < '3.2'
lru-dict>=1.2.0

# Testing (Optional)
pytest>=7.4.0
pytest-asyncio>=0.21.0

# Additional Utilities
tqdm>=4.65.0
colorama>=0.4.6
rich>=13.0.0

# Optional: GPU acceleration (uncomment if you have CUDA)
# torch-audio>=2.0.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118
# torch>=2.0.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118
# torchvision>=0.15.0+cu118 --extra-index-url https://download.pytorch.org/whl/cu118

# Pin numpy to <2.0.0 to avoid ABI conflicts with libraries like opencv
numpy>=1.24.0,<2.0.0
# opencv-python>=4.7.0 # Comment out to prefer headless
opencv-python-headless>=4.8.0 # Forcing headless
Pillow>=10.0.0
ultralytics>=8.0.0 # For YOLOv8 - let's see if it works with headless

# LangChain and related dependencies
langchain>=0.1.0
langchain-community>=0.0.20
langchain-openai>=0.0.5

# Sentence Transformers and its typical dependencies
sentence-transformers>=2.2.0 # Check its transformers dependency
transformers[torch]==4.38.2 # Pinning to a specific compatible version
torch>=2.0.0 
torchvision>=0.15.0

# For API calls and web interaction
requests>=2.28.0
httpx>=0.27.0
serpapi
google-search-results # For SerpAPI tool

# Environment variable management
python-dotenv>=1.0.0

# Utilities
scipy<1.13.0 
numba<0.60.0 

# Other useful libraries
pandas>=1.5.0

# Removed salesforce-lavis as we are using Transformers for BLIP

# Optional dependencies (uncomment as needed)
# redis>=5.0.0
# boto3>=1.34.0
# playwright>=1.40.0
# prometheus_client>=0.17.0 

# GPT-4 Vision Support (much better than BLIP)
openai>=1.0.0

# Additional Utilities
matplotlib>=3.5.0
tqdm>=4.64.0
click>=8.0.0
PyYAML>=6.0

# CLIP 
git+https://github.com/openai/CLIP.git

# Segment Anything Model
segment-anything>=1.0

# Replicate API for Mask2Former
replicate>=0.16.0 